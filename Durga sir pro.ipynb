{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c956009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 900 images for detection training.\n",
      "Loaded 900 images for OCR training.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, BatchNormalization, Dropout, Input, Lambda, Bidirectional, LSTM\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "#print(\"Available devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"c:\\\\mahidhar\\\\datasets\"\n",
    "TRAIN1_IMAGES_DIR = os.path.join(DATA_DIR, \"C:\\\\Users\\\\viswa\\\\Downloads\\\\Licplatesdetection_train\\\\license_plates_detection_train\")\n",
    "TRAIN1_LABELS = os.path.join(DATA_DIR, \"C:\\\\Users\\\\viswa\\\\Downloads\\\\Licplatesdetection_train.csv\")\n",
    "TRAIN2_IMAGES_DIR = os.path.join(DATA_DIR, \"C:\\\\Users\\\\viswa\\\\Downloads\\\\Licplatesrecognition_train\\\\license_plates_recognition_train\")\n",
    "TRAIN2_LABELS = os.path.join(DATA_DIR, \"C:\\\\Users\\\\viswa\\\\Downloads\\\\Licplatesrecognition_train.csv\")\n",
    "TEST_IMAGES_DIR = os.path.join(DATA_DIR, \"C:\\\\Users\\\\viswa\\\\Downloads\\\\test\\\\test\\\\test\")\n",
    "\n",
    "\n",
    "# Resize dimensions\n",
    "DETECTION_IMG_SIZE = (320, 640)  # Height x Width for detection\n",
    "OCR_IMG_SIZE = (32, 128)  # Height x Width for OCR\n",
    "\n",
    "# Character set for OCR\n",
    "CHAR_LIST = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "CHAR_TO_INDEX = {char: i for i, char in enumerate(CHAR_LIST)}\n",
    "NUM_CLASSES = len(CHAR_LIST) + 1  # +1 for CTC blank token\n",
    "\n",
    "# Load Training Set 1 (Bounding Boxes)\n",
    "def load_training_set1():\n",
    "    if not os.path.exists(TRAIN1_LABELS):\n",
    "        print(f\"Error: Labels file {TRAIN1_LABELS} not found.\")\n",
    "        return None, None\n",
    "    try:\n",
    "        df = pd.read_csv(TRAIN1_LABELS)\n",
    "        images, labels = [], []\n",
    "        for idx, row in df.iterrows():\n",
    "            img_path = os.path.join(TRAIN1_IMAGES_DIR, row['img_id'])\n",
    "            if os.path.exists(img_path):\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not load image {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, DETECTION_IMG_SIZE[::-1])  # Width x Height\n",
    "                images.append(img_to_array(img) / 255.0)\n",
    "                labels.append([row['ymin'], row['xmin'], row['ymax'], row['xmax']])\n",
    "            else:\n",
    "                print(f\"Warning: Missing file {img_path}\")\n",
    "        if not images:\n",
    "            print(\"Error: No valid images loaded for detection training.\")\n",
    "            return None, None\n",
    "        print(f\"Loaded {len(images)} images for detection training.\")\n",
    "        return np.array(images), np.array(labels)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Training Set 1: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load Training Set 2 (Character Recognition)\n",
    "def load_training_set2():\n",
    "    if not os.path.exists(TRAIN2_LABELS):\n",
    "        print(f\"Error: Labels file {TRAIN2_LABELS} not found.\")\n",
    "        return None, None\n",
    "    try:\n",
    "        df = pd.read_csv(TRAIN2_LABELS)\n",
    "        images, labels = [], []\n",
    "        for idx, row in df.iterrows():\n",
    "            img_path = os.path.join(TRAIN2_IMAGES_DIR, row['img_id'])\n",
    "            if os.path.exists(img_path):\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not load image {img_path}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, OCR_IMG_SIZE[::-1])  # Width x Height\n",
    "                images.append(np.expand_dims(img, axis=-1) / 255.0)\n",
    "                labels.append(row['text'])\n",
    "            else:\n",
    "                print(f\"Warning: Missing file {img_path}\")\n",
    "        if not images:\n",
    "            print(\"Error: No valid images loaded for OCR training.\")\n",
    "            return None, None\n",
    "        print(f\"Loaded {len(images)} images for OCR training.\")\n",
    "        return np.array(images), labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Training Set 2: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Encode labels for OCR\n",
    "def encode_labels(labels):\n",
    "    max_len = max(len(text) for text in labels)\n",
    "    encoded_labels = [[CHAR_TO_INDEX.get(c, -1) for c in text.upper()] for text in labels]\n",
    "    for i, label in enumerate(encoded_labels):\n",
    "        if -1 in label:\n",
    "            print(f\"Warning: Unknown characters in label '{labels[i]}' mapped to blank token.\")\n",
    "            encoded_labels[i] = [c if c != -1 else NUM_CLASSES - 1 for c in label]\n",
    "    return pad_sequences(encoded_labels, maxlen=max_len, padding='post', value=NUM_CLASSES - 1)\n",
    "\n",
    "# Load datasets\n",
    "X_train1, y_train1 = load_training_set1()\n",
    "X_train2, y_train2 = load_training_set2()\n",
    "\n",
    "if X_train1 is None or X_train2 is None:\n",
    "    print(\"Dataset loading failed. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "# Train License Plate Detection Model\n",
    "detection_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(DETECTION_IMG_SIZE[0], DETECTION_IMG_SIZE[1], 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(4)  # Bounding box coordinates\n",
    "])\n",
    "detection_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "detection_model.fit(X_train1, y_train1, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n",
    "detection_model.save(\"detection_model.h5\")\n",
    "print(\"Detection model training complete and saved as 'detection_model.h5'.\")\n",
    "\n",
    "# Train OCR Model with CTC Loss\n",
    "max_len = max(len(text) for text in y_train2)\n",
    "y_train2_encoded = encode_labels(y_train2)\n",
    "\n",
    "# Define OCR model\n",
    "input_layer = Input(shape=(OCR_IMG_SIZE[0], OCR_IMG_SIZE[1], 1), name='input')  # (32, 128, 1)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)  # (32, 128, 32)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)  # (16, 64, 32)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)  # (16, 64, 64)\n",
    "x = BatchNormalization()(x)  # (16, 64, 64)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)  # (8, 32, 64)\n",
    "\n",
    "# Calculate feature dimension explicitly\n",
    "feature_dim = (OCR_IMG_SIZE[0] // 4) * 64  # 8 * 64 = 512\n",
    "x = Reshape(target_shape=(OCR_IMG_SIZE[1] // 4, feature_dim))(x)  # (32, 512)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)  # (32, 256)\n",
    "x = Dropout(0.25)(x)  # (32, 256)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='output')(x)  # (32, 37)\n",
    "\n",
    "# CTC loss model\n",
    "labels = Input(shape=(max_len,), name='labels')\n",
    "input_length = Input(shape=(1,), name='input_length')\n",
    "label_length = Input(shape=(1,), name='label_length')\n",
    "ctc_loss = Lambda(lambda args: ctc_batch_cost(args[1], args[0], args[2], args[3]), name='ctc')([output_layer, labels, input_length, label_length])\n",
    "ocr_training_model = Model(inputs=[input_layer, labels, input_length, label_length], outputs=ctc_loss)\n",
    "ocr_training_model.compile(optimizer=Adam(learning_rate=0.001), loss=lambda y_true, y_pred: y_pred)\n",
    "\n",
    "# Prepare training data\n",
    "input_length_train = np.ones((len(X_train2), 1)) * (OCR_IMG_SIZE[1] // 4)  # 32 timesteps\n",
    "label_length_train = np.array([[min(len(text), max_len)] for text in y_train2])\n",
    "\n",
    "# Train OCR model\n",
    "detection_model.fit(\n",
    "    X_train1, y_train1, \n",
    "    epochs=20, \n",
    "    batch_size=8, \n",
    "    validation_split=0.1, \n",
    "    verbose=1, \n",
    "    steps_per_epoch=len(X_train1) // 32  # Ensure steps are defined\n",
    ")\n",
    "\n",
    "\n",
    "# Save models\n",
    "ocr_training_model.save(\"ocr_training_model.h5\")\n",
    "ocr_prediction_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "ocr_prediction_model.save(\"ocr_prediction_model.h5\")\n",
    "print(\"OCR model training complete and saved as 'ocr_training_model.h5' and 'ocr_prediction_model.h5'.\")\n",
    "\n",
    "\n",
    "# Define the folder path where models will be saved\n",
    "MODEL_SAVE_PATH = \"saved_models\"\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Save Detection Model\n",
    "detection_model.save(os.path.join(MODEL_SAVE_PATH, \"detection_model.h5\"))\n",
    "\n",
    "# Save OCR Training Model\n",
    "ocr_training_model.save(os.path.join(MODEL_SAVE_PATH, \"ocr_training_model.h5\"))\n",
    "\n",
    "# Save OCR Prediction Model\n",
    "ocr_prediction_model.save(os.path.join(MODEL_SAVE_PATH, \"ocr_prediction_model.h5\"))\n",
    "\n",
    "print(f\"Models saved in '{MODEL_SAVE_PATH}' folder.\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def decode_prediction(pred):\n",
    "    \"\"\"\n",
    "    Decode CTC output from the OCR prediction model.\n",
    "    Input:\n",
    "        - pred: Dense tensor (batch_size, timesteps, num_classes) with softmax probabilities.\n",
    "    Returns:\n",
    "        - Decoded text as a string.\n",
    "    \"\"\"\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]  # timesteps = 32\n",
    "    \n",
    "    # Use CTC greedy decoder on the dense prediction tensor\n",
    "    decoded, _ = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)\n",
    "\n",
    "    # Ensure decoded is a list and get the first element\n",
    "    if isinstance(decoded, (tuple, list)):\n",
    "        decoded = decoded[0]  # Extract tensor if it's in a tuple/list\n",
    "\n",
    "    # Convert tensor to numpy array (handling both SparseTensor and EagerTensor cases)\n",
    "    if isinstance(decoded, tf.SparseTensor):\n",
    "        decoded_dense = tf.sparse.to_dense(decoded, default_value=-1).numpy()\n",
    "    else:\n",
    "        decoded_dense = decoded.numpy()\n",
    "\n",
    "    # Convert indices to characters\n",
    "    result = []\n",
    "    for seq in decoded_dense:\n",
    "        chars = [CHAR_LIST[i] for i in seq if i != -1 and 0 <= i < len(CHAR_LIST)]\n",
    "        result.append(''.join(chars))\n",
    "    \n",
    "    return result[0] if result else \"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model training and setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05aeeeaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'saved_models\\detection_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_896\\4170232842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m detection_model = load_model(\n\u001b[0;32m     22\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_SAVE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"detection_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"custom_loss\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    144\u001b[0m       h5py is not None and (\n\u001b[0;32m    145\u001b[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    198\u001b[0m   \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'saved_models\\detection_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"E:\\\\mahidhar\\\\datasets\"\n",
    "TEST_IMAGES_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "MODEL_SAVE_PATH = \"saved_models\"\n",
    "\n",
    "# Character set for OCR\n",
    "CHAR_LIST = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# Define the custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "# Load trained models\n",
    "detection_model = load_model(\n",
    "    os.path.join(MODEL_SAVE_PATH, \"detection_model.h5\"), \n",
    "    custom_objects={\"custom_loss\": custom_loss}\n",
    ")\n",
    "\n",
    "ocr_model = load_model(\n",
    "    os.path.join(MODEL_SAVE_PATH, \"ocr_prediction_model.h5\"), \n",
    "    custom_objects={\"custom_loss\": custom_loss}\n",
    ")\n",
    "\n",
    "# Function to decode OCR predictions\n",
    "def decode_prediction(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]  \n",
    "    decoded, _ = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)\n",
    "    if isinstance(decoded, (tuple, list)):\n",
    "        decoded = decoded[0]  # Extract tensor if it's in a tuple/list\n",
    "    decoded_dense = tf.sparse.to_dense(decoded, default_value=-1).numpy()\n",
    "    result = []\n",
    "    for seq in decoded_dense:\n",
    "        chars = [CHAR_LIST[i] for i in seq if i != -1 and 0 <= i < len(CHAR_LIST)]\n",
    "        result.append(''.join(chars))\n",
    "    return result[0] if result else \"\"\n",
    "\n",
    "# Function to detect the license plate\n",
    "def predict_license_plate(image):\n",
    "    image_resized = cv2.resize(image, (640, 320)) / 255.0  # Fix input shape\n",
    "    image_resized = np.expand_dims(image_resized, axis=0)  # Add batch dimension\n",
    "    \n",
    "    bbox = detection_model.predict(image_resized)[0]  # Get bounding box prediction\n",
    "\n",
    "    ymin, xmin, ymax, xmax = bbox\n",
    "\n",
    "    ymin = int(ymin * 320)\n",
    "    xmin = int(xmin * 640)\n",
    "    ymax = int(ymax * 320)\n",
    "    xmax = int(xmax * 640)\n",
    "\n",
    "    print(f\"Predicted BBox: ymin={ymin}, xmin={xmin}, ymax={ymax}, xmax={xmax}\")\n",
    "\n",
    "    return ymin, xmin, ymax, xmax\n",
    "\n",
    "# Function to recognize text from cropped license plate\n",
    "def recognize_text(plate_image):\n",
    "    plate_image = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    plate_image = cv2.resize(plate_image, (128, 32)) / 255.0  # Resize & normalize\n",
    "    plate_image = np.expand_dims(plate_image, axis=(0, -1))  # Add batch & channel dimension\n",
    "\n",
    "    predicted_text = ocr_model.predict(plate_image)\n",
    "    return decode_prediction(predicted_text)\n",
    "\n",
    "# Load test images\n",
    "test_filenames = os.listdir(TEST_IMAGES_DIR)\n",
    "X_test = []\n",
    "for filename in test_filenames:\n",
    "    img_path = os.path.join(TEST_IMAGES_DIR, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        X_test.append((filename, img))\n",
    "    else:\n",
    "        print(f\"Warning: Could not read image {filename}\")\n",
    "\n",
    "# Process test images and save predictions\n",
    "predictions = []\n",
    "for filename, img in X_test:\n",
    "    ymin, xmin, ymax, xmax = predict_license_plate(img)\n",
    "\n",
    "    ymin, ymax = max(0, ymin), min(img.shape[0], ymax)\n",
    "    xmin, xmax = max(0, xmin), min(img.shape[1], xmax)\n",
    "\n",
    "    cropped_plate = img[ymin:ymax, xmin:xmax]  \n",
    "\n",
    "    img_with_bbox = img.copy()\n",
    "    cv2.rectangle(img_with_bbox, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)  \n",
    "    cv2.imshow(f\"Detected Plate - {filename}\", img_with_bbox)  \n",
    "\n",
    "    if cropped_plate.size == 0 or ymin == ymax or xmin == xmax:\n",
    "        text_prediction = \"ERROR\"\n",
    "    else:\n",
    "        text_prediction = recognize_text(cropped_plate)\n",
    "\n",
    "        cv2.putText(cropped_plate, text_prediction, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        cv2.imshow(f\"OCR Output - {filename}\", cropped_plate)  \n",
    "\n",
    "    predictions.append((filename, text_prediction))\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"filename\", \"predicted_text\"])\n",
    "submission_df.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Test predictions saved in 'test_predictions.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
